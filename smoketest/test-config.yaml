use_opt_flow: True

# Output debug information e.g. heat numbers on preview
debug: False

# root folder where the source and output folders belong
base_data_folder: "."

# Enables/Disables GPU accelerated classification
use_gpu: false

# source_folder is where the cptv files reside under. It is relative
# to base_data_folder.
source_folder: "smoketest/clips/"

# tracks_folder is where the track data files will be created. It is
# specified relative to base_data_folder.
tracks_folder: "smoketest/classify/"

# which folders (tags) to ignore when selecting cptv files from source_folder
excluded_tags: ['untagged', 'cat', 'dog', 'insect', 'unidentified', 'rabbit', 'hard', 'multi', 'moving',
                  'mouse', 'bird-kiwi', 'for_grant', 'missclassified', 'other']

# Reprocess files which have already been processed.
reprocess: True

# Colour map override to use when exporting to MPEG. If not specified,
# a sensible default colour map is used.
# Note: This is should be a full path. It is not relative to the # base_data_folder.
# previews_colour_map: "custom_colormap.dat"


# Number of worker threads to use.  0 disables worker pool and forces a single thread.
worker_threads: 0

# x and y resolution of thermal camera
res_x: 160
res_y: 120

tracking:
    #
    #  Tracking algorithm
    #

    # Default algorithm used to calculate the image background.   Must be "preview" or "stats"
    # Preview uses the preview time in the video (if it exists in the meta for cptv file)
    # Stats uses a statistical analysis of the whole video to get background levels
    background_calc: preview

    # these parameters are associated with the preview background method
    preview:
        # Temp_thresh is calculated based on the preview min, max and mean, and temp_thresh value
        dynamic_thresh: True
        
        # When calculating the background ignore the last frames of the preview as the motion detection
        # will still be triggering during this time.
        ignore_frames: 2

        # Minimum raw (temperature) value to be tracked
        temp_thresh: 2900

        # Minimum raw temperature difference between background and track
        delta_thresh: 20

    # these parameters are associated with the stats background method
    stats:
        # auto threshold needs to find a near maximum value to calculate the threshold level
        # a better solution might be the mean of the max of each frame?
        threshold_percentile: 99.9

        # minimum allowed threshold for number of pixels changed from average background, smaller values detect more objects, but bring up additional false positives
        min_threshold: 30

        # minimum allowed threshold for number of pixels changed from average background, smaller values detect more objects, but bring up additional false positives
        max_threshold: 50


    # any clips with a mean temperature hotter than this will be excluded
    max_mean_temperature_threshold: 10000

    # any clips with a temperature dynamic range greater than this will be excluded
    max_temperature_range_threshold: 10000

    # measures how different pixels are from estimated background, if they are on average less different than this then
    # video is considered to be static.
    static_background_threshold: 4.0

    # number of pixels round the edge to ignore due to strange values
    edge_pixels: 1

    # number of pixels around object to pad.
    # Note: frame_padding must be at least 3 or some frames may be too small for classification and program may crash
    frame_padding: 4

    # dilation pixels:  This is the number of pixels to grow the mask of interesting bits.
    # The higher the value, the further apart things (bits of animal, or animals) will be linked together as one object
    dilation_pixels: 2

    # wait this many frames for animal to "reappear" after it is last detected.
    remove_track_after_frames: 9

    # when enabled smooths tracks so that track dimensions do not change too quickly.
    track_smoothing: False

    high_quality_optical_flow: False

    # how much to threshold thermal before calculating optical flow.
    flow_threshold: 40

    # maximum number of tracks to extract from a clip.  Takes the n best tracks.
    max_tracks: 10

    areas_of_interest:
        # minimum pixels of interest each area of interest should have.
        min_mass: 4.0

        # minimum variation of pixels between then frame and previous for each area of interest.
        pixel_variance: 2.0

        # strategy to use when dealing with regions of interest that are cropped against the side of the frame
        # in general these regions often do not have enough information to accurately identify the animal.
        # options are
        # 'all': All cropped regions are included, good for classifier
        # 'cautious': Regions that are only cropped a bit are let through, this is good for training data
        # 'none': No cropped regions are permitted.  This is the most safe.
        cropped_regions_strategy: "cautious"

    filters:
        # regions with a movement less than this have their tracking scored based of x,y matching, instead of than mid points
        moving_vel_thresh: 4
        
        # discard any tracks that overlap with other tracks more than this.   T than this length in seconds
        track_overlap_ratio: 0.5

        # discard any tracks shorter than this length in seconds
        min_duration_secs: 3.0

        # dicard any tracks that do not move enough, (move less than this)
        track_min_offset: 4.0

        # discard tracks that do not have enough delta within the window (i.e. pixels that change a lot)
        track_min_delta: 1.0

        # discard tracks that do not have enough enough average mass.
        track_min_mass: 2.0

    # Add verbose logging about tracks generated
    verbose: False

    # Minimum confidence of track tag to accept
    min_tag_confidence: 0.8
load:
    # precidence of tags (lower first)
    tag_precedence:
        0: ["bird", "false-positive", "hedgehog", "possum", "rodent", "mustelid", "cat", "kiwi", "dog", "leporidae", "human", "insect", "pest"]
        1: ["unidentified", "other"]
        2: ["part","bad track"]
    
    # Use fast BLOSC compression (requires plugin), when saving tracks to database
    enable_compression: False

    # Includes the filtered channel in tracks database.  This is typically not used.  If compression is enabled the
    # filesize can be reduced by not including it.
    include_filtered_channel: False

    # Create a MP4 preview of the recording.  Options are "none", "raw", "boxes", "classified", "tracking"
    # none - won't create a preview video
    # raw - just the video (no classification or tracks)
    # boxes - show track boxes but no text
    # classified - show tracks and classification values
    # tracking -  four frame video view, including thermal, filtered, mask and flow layers
    preview: "boxes"

    #cache buffer frame to disk reducing memory usage
    cache_to_disk: True
train:
    hyper_params:
        # training
        batch_size: 16
        learning_rate: 0.0004
        learning_rate_decay: 1.0
        l2_reg: 0
        label_smoothing: 0.1
        keep_prob: 0.2

        # model
        batch_norm: true
        lstm_units: 256
        enable_flow: true

        # augmentation
        augmentation: true
        thermal_threshold: 10
        scale_frequency: 0.5

    # Number of epochs to train for
    epochs: 30

    # Location to write various training outputs to. Relative to
    # base_data_folder. Defaults to "training"
    # train_dir: "training"

classify_tracking:
    # Note: frame_padding must be at least 3 or some frames may be too small for classification
    frame_padding: 4
    high_quality_optical_flow: True
    filters:
        track_overlap_ratio: 0.5
        min_duration_secs: 1.0
        track_min_offset: 4.0
        track_min_delta: 1.0
        track_min_mass: 2.0

classify:
    # Writes metadata to standard out instead of a file with extension .txt
    meta_to_stdout : True

    # Path to pretrained Model use for classification (This should be the base filename without any extension)
    model: "./models/model_hq-0.966"

    # Create a MP4 preview after classification of recording.  Options are "none", "raw", "classified", "tracking"
    # See extract:preview for details on each option.
    preview: "boxes"

    # folder is where classifier output and mp4s will be created.  It is specified relative to the base_data_folder
    classify_folder: "smoketest/clips"

    #cache buffer frame to disk reducing memory usage
    cache_to_disk: True
evaluate:
    # Evalulates results against pre-tagged ground truth.
    show_extended_evaluation: False

    # number of seconds between clips required to trigger a a new visit
    new_visit_threshold: 180

    # false positive's and 'none' can be mapped to the same label as they represent the same idea.
    null_tags: ["false-positive", "none", "no-tag"]
    
    # Labels 
    labels : ["bird", "false-positive", "hedgehog", "possum", "rat", "stoat"]
build:
    #file containing clips to be banned relative to running path
    banned_clips_file: "excluded_clips.txt"

    # uses split from previous run
    use_previous_split: True

    # file to load previous split from
    previous_split: template.dat

    # labels to ignore
    ignore_labels: ["false-positive"]

    # if true removes any trapped animal footage from dataset.
    # trapped footage can be a problem as there tends to be lots of it and the animals do not move in a normal way.
    # however, bin weighting will generally take care of the excessive footage problem.
    excluded_trap: True

    # sets a maximum number of segments per bin, where the cap is this many standard deviations above the norm.
    # bins with more than this number of segments will be weighted lower so that their segments are not lost, but
    # will be sampled less frequently.
    cap_bin_weight: 1.5

    # adjusts the weight for each animal class.  Setting this lower for animals that are less represented can help
    # with training, otherwise the few examples we have will be used excessively.  This also helps build a prior for
    # the class suggesting that the class is more or less likely.  For example bumping up the human weighting will cause
    # the classifier lean towards guessing human when it is not sure.

    # xxx this doesn't actually work, and should be removed.
    label_weights: {"bird-kiwi": 0.1}

    # clips after this date will be ignored.
    # note: this is based on the UTC date.
    clip_end_date: "2020-12-31"

    # minimum average mass for test segment
    test_min_mass: 30

    train_min_mass: 20

    # any day with a track this number of second or longer will be excluded from the validation set.
    # this is because it would be more useful to train on the long track, and we don't want the track to dominate the
    # validation set (otherwise a single track could end up being 50% of the data)
    max_validation_set_track_duration: 120

    # number of segments to include in test set for each class (multiplied by label weights)
    test_set_count: 1

    # minimum number of bins used for test set
    test_set_bins: 1

    # number of seconds each segment should be
    segment_length: 3

    # number of seconds segments are spaced apart
    segment_spacing: 1
